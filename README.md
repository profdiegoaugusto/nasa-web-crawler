# üöÄ NASA Web Crawler 

Rastreador Web do cronograma de lan√ßamento da NASA.

## Criando Um Novo Projeto

Antes de come√ßarmos nossa coleta de dados, voc√™ precisa configurar um novo projeto Scrapy; caso contr√°rio nada funcionar√°! 
Usando a ferramenta de *Terminal* do seu Sistema Operacional, entre na pasta que voc√™ vai guardar seu c√≥digo e digite o comando abaixo:

```python
scrapy startproject nasa_web_crawler
```

Este comando vai criar uma nova pasta com o seguinte conte√∫do:

```bash
nasa_web_crawler/
    
    scrapy.cfg            # Arquivo de configura√ß√£o de implanta√ß√£o.

    nasa_web_crawler/     # M√≥dulo Python do Projeto: voc√™ vai programar seu rastreador usando os arquivos aqui dentro
        
        __init__.py

        items.py          # Arquivo de Defini√ß√£o:

        middlewares.py    # Middlewares do Projeto:

        pipelines.py      # Pipelines do Projeto: 

        settings.py       # Arquivo de Configura√ß√£o do Projeto:

        spiders/          # IMPORTANTE: diret√≥rio onde, daqui a pouco, voc√™ colocar√° seus coletores (Spiders)
            __init__.py
```

## Criando Um Novo Coletor (Spider)

**Spiders** s√£o classes que voc√™ define para que o Scrapy as use para extrair informa√ß√µes de um site ou de um grupo de sites. Elas devem ser subclasses da classe `Spider` e definem as solicita√ß√µes iniciais a serem feitas. Opcionalmente, os *Spiders* podem descrever como o coletor vai seguir os links nas p√°ginas e como ser√° feito o *parser* do conte√∫do da p√°gina baixada para extra√ß√£o dados.

O c√≥digo abaixo √© nosso coletor (*Spider*) do [Cronograma de Lan√ßamento da NASA](https://www.nasa.gov/launchschedule/), copie e cole o c√≥digo em um novo arquivo chamado `cronograma_nasa.py` dentro da pasta `nasa_web_crawler/spiders`.

```python

```

### genspider

√â poss√≠vel criar um novo *Spider* usando a ferramenta de linha de comando do *Terminal*, para isso, usaremos a sintaxe abaixo:

```bash
scrapy genspider <nome> <dom√≠nio>
```

* `<nome>`: define o nome do seu coletor (Spider);
* `<dom√≠nio>`: define o endere√ßo da web (URL) onde ser√° feita a coleta de dados.

Este comando cria um novo coletor (*Spider*) dentro da pasta atual ou na pasta de `spiders` do projeto atual. 
Lembrando que os par√¢metros `<nome>` e `<dom√≠nio>` **s√£o obrigat√≥rios** para que o comando funcione!

#### Exemplo

Entre no diret√≥rio `nasa_web_crawler/nasa_web_crawler` e digite o comando:

```bash
scrapy genspider cronograma_lancamento_nasa https://www.nasa.gov/launchschedule/
```

Essa instru√ß√£o cria um novo coletor (*Spider*) chamando: `cronograma_lancamento_nasa.py`; dentro da pasta `nasa_web_crawler/spiders` contendo o seguinte c√≥digo gerado autom√°ticamente:

```python
# -*- coding: utf-8 -*-
import scrapy


class CronogramaLancamentoNasaSpider(scrapy.Spider):
    name = 'cronograma_lancamento_nasa'
    allowed_domains = ['https://www.nasa.gov/launchschedule/']
    start_urls = ['http://https://www.nasa.gov/launchschedule//']

    def parse(self, response):
        pass

```

Observe que o par√¢metro `<nome>` configurou o nome do coletor na linha 6 `name = 'cronograma_lancamento_nasa'` e o par√¢metro `<dom√≠nio>` definiu os atributos `allowed_domains` e `start_urls` que especificam respectivamente a lista de dom√≠nios permitidos que o coletor pode rastrear e lista de URLs de onde o coletor (*Spider*) come√ßar√° a rastrear.

## Extraindo Dados

Ap√≥s configurar seu Rastreador Web (Web Crawler), o primeiro passo que voc√™ precisa fazer para coletar dados em p√°ginas da Web √© estudar a estrutura do documento `HTML` e definir qual ser√° a sua estrat√©gia para obter os dados. No nosso caso queremos coletar as seguintes informa√ß√µes dos pr√≥ximos lan√ßamentos de foguetes da NASA: 

* **Imagem:** URL da imagem de divulga√ß√£o do lan√ßamento;
* **Date:** data do lan√ßamento;
* **Mission:** nome da miss√£o;
* **URL Mission:** URL da P√°gina da Miss√£o; 
* **Description:** descri√ß√£o da miss√£o;

![Card de Lan√ßamento](img/nasa_website.png "Website NASA: Cronograma de Lan√ßamentos de Foguete")

Ao utilizar a ferramenta de inspe√ß√£o de c√≥digo fonte do navegador, descobrimos que os nossos dados est√£o estruturados da seguinte maneira:

![Card de Lan√ßamento](img/card.png "Card dos Pr√≥ximos Lan√ßamentos de Foguete da NASA")

```html
<div class="launch-event clearfix">

    <div class="launch-image">
        <a href="https://www.nasa.gov/specials/dm2/">
            <img src="/sites/default/files/styles/image_card_4x3_ratio/public/thumbnails/image/dm2_flag_041120_dsc_1356-asretouch.jpg">
        </a>
    </div>

    <div class="launch-info">

        <div id="ember697" class="ember-view">
            <div class="date">
                <span class="launch-label">Date: </span>May 27, 2020 - 4:32 p.m. Eastern
            </div>
        </div>

        <div class="title">
            <span class="launch-label">Mission:</span>
            <a href="https://www.nasa.gov/specials/dm2/">Commercial Crew SpaceX Demo-2 Flight Test (Crewed)</a>
        </div>

        <div class="description">
            <span class="launch-label">Description:</span> SpaceX‚Äôs Crew Dragon Demo-2 mission is a flight test with crew, prior to certification of systems by NASA for operational missions to the International Space Station. NASA astronauts Robert Behnken and Douglas Hurley will fly on the Crew Dragon spacecraft, lifting off on a Falcon 9 rocket from Launch Complex 39A in Florida.
        </div>
        <!---->
    </div>
</div>
```


* **Imagem:** `div.launch-event/div.launch-image/a/img`;
* **Date:** `div.launch-event/div.launch-info/div.ember-view/div.date`;
* **Mission:** `div.launch-event/div.launch-info/div.title/a`;
* **URL Mission:** `div.launch-event/div.launch-info/div.title/a`; 
* **Description:** `div.launch-event/div.launch-info/div.description`.

Ap√≥s fazer este estudo e mapeamento da estrutura do `HTML` da p√°gina Web que ser√° feita a coleta, o pr√≥ximo passo √© programaramos nosso coletor (*Spider*) para visitar cada um destes elementos HTML que guardam nossos dados e fazermos a coleta de dados. Como voc√™ deve imaginar, iremos utilizar os Seletores CSS para acessar cada um dos elementos HTML na √°rvore DOM da p√°gina para pegar nossos dados.

